{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e5c6706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brocode.code_analysis import MultiScriptContextBuilder\n",
    "from pathlib import Path\n",
    "\n",
    "code_dir = Path(\"../brocode\")\n",
    "package_dir = Path(\"./package\")\n",
    "script_builder = MultiScriptContextBuilder()\n",
    "code_contexts = script_builder.build_contexts([\n",
    "    # code_dir / \"cli.py\",\n",
    "    # code_dir / \"register.py\",\n",
    "    # code_dir / \"chat.py\",\n",
    "    # code_dir / \"code_analysis.py\",\n",
    "    package_dir / \"bye_world.py\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b852db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['package\\\\bye_world.py'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_contexts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "422eceb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODE:\n",
      "```python\n",
      "from typing import Optional\n",
      "\n",
      "class BaseBye:\n",
      "    \"\"\"This is a base class\"\"\"\n",
      "    def __init__(self, name:Optional[str]=\"James\", message:Optional[str]=\"Base\") -> None:\n",
      "        self.name = name\n",
      "        self.message = message\n",
      "    def say_bye(self)->str:\n",
      "        \"\"\"This is a function to say bye to a person\n",
      "        \n",
      "        Return:\n",
      "            str : a bye message\n",
      "        \"\"\"\n",
      "        return \"Bye {message}: {name}!\".format(message=self.message, name=self.name)\n",
      "\n",
      "class ByeWorld(BaseBye):\n",
      "    \"\"\"This is a class for saying good bye\n",
      "    Args:\n",
      "        name (str) : a name to say good bye to, default is James\n",
      "    \"\"\"\n",
      "    def __init__(self, name:Optional[str]=\"James\") -> None:\n",
      "        super().__init__(name=name, message=\"World\")\n",
      "    \n",
      "class ByeEarth(BaseBye):\n",
      "    \"\"\"This is a class for saying good bye to earth\n",
      "    Args:\n",
      "        name (str) : a name to say good bye to, default is James\n",
      "    \"\"\"\n",
      "    def __init__(self, name:Optional[str]=\"James\") -> None:\n",
      "        super().__init__(name=name, message=\"Earth\")\n",
      "```\n",
      "\n",
      "STRUCTURE SUMMARY:\n",
      "Classes:\n",
      "  - BaseBye (methods: __init__, say_bye)\n",
      "  - ByeWorld extends BaseBye (methods: __init__)\n",
      "  - ByeEarth extends BaseBye (methods: __init__)\n",
      "Imports: typing.Optional\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(code_contexts['package\\\\bye_world.py'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a606eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brollm import BaseLLM\n",
    "# from brocode.register import register_llm\n",
    "import requests\n",
    "from typing import Dict, Any\n",
    "\n",
    "class LocalLLM(BaseLLM):\n",
    "    def __init__(self):\n",
    "        self.model_name = \"gpt-oss:latest\"\n",
    "        self.base_url = \"http://localhost:11434\"\n",
    "        self.temperature = 0.0\n",
    "\n",
    "    def UserMessage(self, text: str, **kwargs) -> Dict[str, Any]:\n",
    "        return {\"role\": \"user\", \"content\": text}\n",
    "\n",
    "    def AIMessage(self, text: str) -> Dict[str, Any]:\n",
    "        return {\"role\": \"assistant\", \"content\": text}\n",
    "\n",
    "    def SystemMessage(self, text: str) -> Dict[str, Any]:\n",
    "        return {\"role\": \"system\", \"content\": text}    \n",
    "    \n",
    "    def run(self, system_prompt:str, messages:list[dict])->str:\n",
    "        all_messages = [self.SystemMessage(system_prompt)] + messages\n",
    "        response = requests.post(\n",
    "            \"{base_url}/api/chat\".format(base_url=self.base_url), \n",
    "            json={\n",
    "                \"model\": self.model_name,\n",
    "                \"messages\": all_messages,\n",
    "                \"stream\": False,\n",
    "                \"options\": {\"temperature\": self.temperature}\n",
    "            }\n",
    "        )\n",
    "        return response.json()['message']['content']\n",
    "model = LocalLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57cdec49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brocode.actions.code_generator import CodeGenerator\n",
    "from brocode.actions import Shared, BaseModel, Field\n",
    "from broprompt import Prompt\n",
    "prompt = Prompt.from_markdown(\"../brocode/prompt_hub/code_generator.md\")\n",
    "cg = CodeGenerator(\n",
    "    system_prompt=prompt.str,\n",
    "    model=model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3ae01ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How do you want the output?\n",
      "1. Code block in terminal\n",
      "2. Save to file\n",
      "#!/usr/bin/env python\n",
      "# -*- coding: utf-8 -*-\n",
      "\n",
      "\"\"\"\n",
      "Simple AutoEncoder implementation using PyTorch.\n",
      "\n",
      "The module defines three classes:\n",
      "\n",
      "* :class:`Encoder` – maps the input to a latent representation.\n",
      "* :class:`Decoder` – reconstructs the input from the latent vector.\n",
      "* :class:`AutoEncoder` – combines the encoder and decoder into a single\n",
      "  :class:`torch.nn.Module`.\n",
      "\n",
      "The network is intentionally lightweight and suitable for educational\n",
      "purposes or quick prototyping.  It can be extended by inheriting from the\n",
      "base classes or by replacing the internal layers.\n",
      "\"\"\"\n",
      "\n",
      "from __future__ import annotations\n",
      "\n",
      "from dataclasses import dataclass\n",
      "from typing import Iterable, Tuple\n",
      "\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "\n",
      "\n",
      "class Encoder(nn.Module):\n",
      "    \"\"\"\n",
      "    Encoder network that compresses the input into a latent vector.\n",
      "\n",
      "    The architecture consists of a single linear layer followed by a\n",
      "    ReLU activation.  The dimensionality of the latent space is\n",
      "    configurable via the ``latent_dim`` argument.\n",
      "\n",
      "    Args:\n",
      "        input_dim: Dimensionality of the input features.\n",
      "        latent_dim: Dimensionality of the latent representation.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, input_dim: int, latent_dim: int) -> None:\n",
      "        super().__init__()\n",
      "        if input_dim <= 0:\n",
      "            raise ValueError(\"input_dim must be a positive integer\")\n",
      "        if latent_dim <= 0:\n",
      "            raise ValueError(\"latent_dim must be a positive integer\")\n",
      "\n",
      "        self.linear = nn.Linear(input_dim, latent_dim)\n",
      "\n",
      "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
      "        \"\"\"\n",
      "        Forward pass of the encoder.\n",
      "\n",
      "        Args:\n",
      "            x: Input tensor of shape ``(batch_size, input_dim)``.\n",
      "\n",
      "        Returns:\n",
      "            Latent representation tensor of shape\n",
      "            ``(batch_size, latent_dim)``.\n",
      "        \"\"\"\n",
      "        if x.ndim != 2 or x.size(1) != self.linear.in_features:\n",
      "            raise ValueError(\n",
      "                f\"Expected input of shape (batch_size, {self.linear.in_features}), \"\n",
      "                f\"got {x.shape}\"\n",
      "            )\n",
      "        return F.relu(self.linear(x))\n",
      "\n",
      "\n",
      "class Decoder(nn.Module):\n",
      "    \"\"\"\n",
      "    Decoder network that reconstructs the input from a latent vector.\n",
      "\n",
      "    The architecture mirrors the encoder: a single linear layer followed\n",
      "    by a Sigmoid activation to keep the output in the range [0, 1].\n",
      "\n",
      "    Args:\n",
      "        latent_dim: Dimensionality of the latent representation.\n",
      "        output_dim: Dimensionality of the reconstructed output.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, latent_dim: int, output_dim: int) -> None:\n",
      "        super().__init__()\n",
      "        if latent_dim <= 0:\n",
      "            raise ValueError(\"latent_dim must be a positive integer\")\n",
      "        if output_dim <= 0:\n",
      "            raise ValueError(\"output_dim must be a positive integer\")\n",
      "\n",
      "        self.linear = nn.Linear(latent_dim, output_dim)\n",
      "\n",
      "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
      "        \"\"\"\n",
      "        Forward pass of the decoder.\n",
      "\n",
      "        Args:\n",
      "            z: Latent tensor of shape ``(batch_size, latent_dim)``.\n",
      "\n",
      "        Returns:\n",
      "            Reconstructed tensor of shape ``(batch_size, output_dim)``.\n",
      "        \"\"\"\n",
      "        if z.ndim != 2 or z.size(1) != self.linear.in_features:\n",
      "            raise ValueError(\n",
      "                f\"Expected latent input of shape (batch_size, {self.linear.in_features}), \"\n",
      "                f\"got {z.shape}\"\n",
      "            )\n",
      "        return torch.sigmoid(self.linear(z))\n",
      "\n",
      "\n",
      "class AutoEncoder(nn.Module):\n",
      "    \"\"\"\n",
      "    AutoEncoder that combines an :class:`Encoder` and a :class:`Decoder`.\n",
      "\n",
      "    The network can be used for dimensionality reduction, denoising,\n",
      "    or as a pre‑training step for other models.\n",
      "\n",
      "    Args:\n",
      "        input_dim: Dimensionality of the input features.\n",
      "        latent_dim: Dimensionality of the latent representation.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, input_dim: int, latent_dim: int) -> None:\n",
      "        super().__init__()\n",
      "        self.encoder = Encoder(input_dim, latent_dim)\n",
      "        self.decoder = Decoder(latent_dim, input_dim)\n",
      "\n",
      "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
      "        \"\"\"\n",
      "        Forward pass of the autoencoder.\n",
      "\n",
      "        Args:\n",
      "            x: Input tensor of shape ``(batch_size, input_dim)``.\n",
      "\n",
      "        Returns:\n",
      "            Reconstructed tensor of shape ``(batch_size, input_dim)``.\n",
      "        \"\"\"\n",
      "        z = self.encoder(x)\n",
      "        return self.decoder(z)\n",
      "\n",
      "    def encode(self, x: torch.Tensor) -> torch.Tensor:\n",
      "        \"\"\"\n",
      "        Encode the input into the latent space.\n",
      "\n",
      "        Args:\n",
      "            x: Input tensor of shape ``(batch_size, input_dim)``.\n",
      "\n",
      "        Returns:\n",
      "            Latent representation tensor of shape\n",
      "            ``(batch_size, latent_dim)``.\n",
      "        \"\"\"\n",
      "        return self.encoder(x)\n",
      "\n",
      "    def decode(self, z: torch.Tensor) -> torch.Tensor:\n",
      "        \"\"\"\n",
      "        Decode a latent vector back into the input space.\n",
      "\n",
      "        Args:\n",
      "            z: Latent tensor of shape ``(batch_size, latent_dim)``.\n",
      "\n",
      "        Returns:\n",
      "            Reconstructed tensor of shape ``(batch_size, input_dim)``.\n",
      "        \"\"\"\n",
      "        return self.decoder(z)\n",
      "\n",
      "\n",
      "# --------------------------------------------------------------------------- #\n",
      "# Example usage\n",
      "# --------------------------------------------------------------------------- #\n",
      "def _example() -> None:\n",
      "    \"\"\"\n",
      "    Demonstrates how to instantiate and train the AutoEncoder on dummy data.\n",
      "    \"\"\"\n",
      "    # Hyper‑parameters\n",
      "    input_dim = 784  # e.g., flattened 28x28 images\n",
      "    latent_dim = 32\n",
      "    batch_size = 64\n",
      "    epochs = 5\n",
      "    learning_rate = 1e-3\n",
      "\n",
      "    # Dummy dataset: random noise\n",
      "    data = torch.randn(1000, input_dim)\n",
      "\n",
      "    # DataLoader\n",
      "    dataset = torch.utils.data.TensorDataset(data)\n",
      "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
      "\n",
      "    # Model, loss, optimizer\n",
      "    model = AutoEncoder(input_dim, latent_dim)\n",
      "    criterion = nn.MSELoss()\n",
      "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
      "\n",
      "    # Training loop\n",
      "    model.train()\n",
      "    for epoch in range(epochs):\n",
      "        epoch_loss = 0.0\n",
      "        for batch, in loader:\n",
      "            optimizer.zero_grad()\n",
      "            recon = model(batch)\n",
      "            loss = criterion(recon, batch)\n",
      "            loss.backward()\n",
      "            optimizer.step()\n",
      "            epoch_loss += loss.item() * batch.size(0)\n",
      "\n",
      "        epoch_loss /= len(loader.dataset)\n",
      "        print(f\"Epoch {epoch + 1}/{epochs} – Loss: {epoch_loss:.4f}\")\n",
      "\n",
      "    # Inference example\n",
      "    model.eval()\n",
      "    with torch.no_grad():\n",
      "        sample = data[:5]\n",
      "        latent = model.encode(sample)\n",
      "        recon = model.decode(latent)\n",
      "        print(\"Original shape:\", sample.shape)\n",
      "        print(\"Latent shape:\", latent.shape)\n",
      "        print(\"Reconstructed shape:\", recon.shape)\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    _example()\n",
      "Code saved to package\\ae_torch.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<brocode.actions.Shared at 0x2960d315310>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared = Shared()\n",
    "cg.run(shared=shared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7fb14ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(shared.code_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98914ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "#!/usr/bin/env python\n",
      "# -*- coding: utf-8 -*-\n",
      "\n",
      "\"\"\"\n",
      "Simple AutoEncoder implementation using PyTorch.\n",
      "\n",
      "The module defines three classes:\n",
      "\n",
      "* :class:`Encoder` – maps the input to a latent representation.\n",
      "* :class:`Decoder` – reconstructs the input from the latent vector.\n",
      "* :class:`AutoEncoder` – combines the encoder and decoder into a single\n",
      "  :class:`torch.nn.Module`.\n",
      "\n",
      "The network is intentionally lightweight and suitable for educational\n",
      "purposes or quick prototyping.  It can be extended by inheriting from the\n",
      "base classes or by replacing the internal layers.\n",
      "\"\"\"\n",
      "\n",
      "from __future__ import annotations\n",
      "\n",
      "from dataclasses import dataclass\n",
      "from typing import Iterable, Tuple\n",
      "\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "\n",
      "\n",
      "class Encoder(nn.Module):\n",
      "    \"\"\"\n",
      "    Encoder network that compresses the input into a latent vector.\n",
      "\n",
      "    The architecture consists of a single linear layer followed by a\n",
      "    ReLU activation.  The dimensionality of the latent space is\n",
      "    configurable via the ``latent_dim`` argument.\n",
      "\n",
      "    Args:\n",
      "        input_dim: Dimensionality of the input features.\n",
      "        latent_dim: Dimensionality of the latent representation.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, input_dim: int, latent_dim: int) -> None:\n",
      "        super().__init__()\n",
      "        if input_dim <= 0:\n",
      "            raise ValueError(\"input_dim must be a positive integer\")\n",
      "        if latent_dim <= 0:\n",
      "            raise ValueError(\"latent_dim must be a positive integer\")\n",
      "\n",
      "        self.linear = nn.Linear(input_dim, latent_dim)\n",
      "\n",
      "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
      "        \"\"\"\n",
      "        Forward pass of the encoder.\n",
      "\n",
      "        Args:\n",
      "            x: Input tensor of shape ``(batch_size, input_dim)``.\n",
      "\n",
      "        Returns:\n",
      "            Latent representation tensor of shape\n",
      "            ``(batch_size, latent_dim)``.\n",
      "        \"\"\"\n",
      "        if x.ndim != 2 or x.size(1) != self.linear.in_features:\n",
      "            raise ValueError(\n",
      "                f\"Expected input of shape (batch_size, {self.linear.in_features}), \"\n",
      "                f\"got {x.shape}\"\n",
      "            )\n",
      "        return F.relu(self.linear(x))\n",
      "\n",
      "\n",
      "class Decoder(nn.Module):\n",
      "    \"\"\"\n",
      "    Decoder network that reconstructs the input from a latent vector.\n",
      "\n",
      "    The architecture mirrors the encoder: a single linear layer followed\n",
      "    by a Sigmoid activation to keep the output in the range [0, 1].\n",
      "\n",
      "    Args:\n",
      "        latent_dim: Dimensionality of the latent representation.\n",
      "        output_dim: Dimensionality of the reconstructed output.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, latent_dim: int, output_dim: int) -> None:\n",
      "        super().__init__()\n",
      "        if latent_dim <= 0:\n",
      "            raise ValueError(\"latent_dim must be a positive integer\")\n",
      "        if output_dim <= 0:\n",
      "            raise ValueError(\"output_dim must be a positive integer\")\n",
      "\n",
      "        self.linear = nn.Linear(latent_dim, output_dim)\n",
      "\n",
      "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
      "        \"\"\"\n",
      "        Forward pass of the decoder.\n",
      "\n",
      "        Args:\n",
      "            z: Latent tensor of shape ``(batch_size, latent_dim)``.\n",
      "\n",
      "        Returns:\n",
      "            Reconstructed tensor of shape ``(batch_size, output_dim)``.\n",
      "        \"\"\"\n",
      "        if z.ndim != 2 or z.size(1) != self.linear.in_features:\n",
      "            raise ValueError(\n",
      "                f\"Expected latent input of shape (batch_size, {self.linear.in_features}), \"\n",
      "                f\"got {z.shape}\"\n",
      "            )\n",
      "        return torch.sigmoid(self.linear(z))\n",
      "\n",
      "\n",
      "class AutoEncoder(nn.Module):\n",
      "    \"\"\"\n",
      "    AutoEncoder that combines an :class:`Encoder` and a :class:`Decoder`.\n",
      "\n",
      "    The network can be used for dimensionality reduction, denoising,\n",
      "    or as a pre‑training step for other models.\n",
      "\n",
      "    Args:\n",
      "        input_dim: Dimensionality of the input features.\n",
      "        latent_dim: Dimensionality of the latent representation.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, input_dim: int, latent_dim: int) -> None:\n",
      "        super().__init__()\n",
      "        self.encoder = Encoder(input_dim, latent_dim)\n",
      "        self.decoder = Decoder(latent_dim, input_dim)\n",
      "\n",
      "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
      "        \"\"\"\n",
      "        Forward pass of the autoencoder.\n",
      "\n",
      "        Args:\n",
      "            x: Input tensor of shape ``(batch_size, input_dim)``.\n",
      "\n",
      "        Returns:\n",
      "            Reconstructed tensor of shape ``(batch_size, input_dim)``.\n",
      "        \"\"\"\n",
      "        z = self.encoder(x)\n",
      "        return self.decoder(z)\n",
      "\n",
      "    def encode(self, x: torch.Tensor) -> torch.Tensor:\n",
      "        \"\"\"\n",
      "        Encode the input into the latent space.\n",
      "\n",
      "        Args:\n",
      "            x: Input tensor of shape ``(batch_size, input_dim)``.\n",
      "\n",
      "        Returns:\n",
      "            Latent representation tensor of shape\n",
      "            ``(batch_size, latent_dim)``.\n",
      "        \"\"\"\n",
      "        return self.encoder(x)\n",
      "\n",
      "    def decode(self, z: torch.Tensor) -> torch.Tensor:\n",
      "        \"\"\"\n",
      "        Decode a latent vector back into the input space.\n",
      "\n",
      "        Args:\n",
      "            z: Latent tensor of shape ``(batch_size, latent_dim)``.\n",
      "\n",
      "        Returns:\n",
      "            Reconstructed tensor of shape ``(batch_size, input_dim)``.\n",
      "        \"\"\"\n",
      "        return self.decoder(z)\n",
      "\n",
      "\n",
      "# --------------------------------------------------------------------------- #\n",
      "# Example usage\n",
      "# --------------------------------------------------------------------------- #\n",
      "def _example() -> None:\n",
      "    \"\"\"\n",
      "    Demonstrates how to instantiate and train the AutoEncoder on dummy data.\n",
      "    \"\"\"\n",
      "    # Hyper‑parameters\n",
      "    input_dim = 784  # e.g., flattened 28x28 images\n",
      "    latent_dim = 32\n",
      "    batch_size = 64\n",
      "    epochs = 5\n",
      "    learning_rate = 1e-3\n",
      "\n",
      "    # Dummy dataset: random noise\n",
      "    data = torch.randn(1000, input_dim)\n",
      "\n",
      "    # DataLoader\n",
      "    dataset = torch.utils.data.TensorDataset(data)\n",
      "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
      "\n",
      "    # Model, loss, optimizer\n",
      "    model = AutoEncoder(input_dim, latent_dim)\n",
      "    criterion = nn.MSELoss()\n",
      "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
      "\n",
      "    # Training loop\n",
      "    model.train()\n",
      "    for epoch in range(epochs):\n",
      "        epoch_loss = 0.0\n",
      "        for batch, in loader:\n",
      "            optimizer.zero_grad()\n",
      "            recon = model(batch)\n",
      "            loss = criterion(recon, batch)\n",
      "            loss.backward()\n",
      "            optimizer.step()\n",
      "            epoch_loss += loss.item() * batch.size(0)\n",
      "\n",
      "        epoch_loss /= len(loader.dataset)\n",
      "        print(f\"Epoch {epoch + 1}/{epochs} – Loss: {epoch_loss:.4f}\")\n",
      "\n",
      "    # Inference example\n",
      "    model.eval()\n",
      "    with torch.no_grad():\n",
      "        sample = data[:5]\n",
      "        latent = model.encode(sample)\n",
      "        recon = model.decode(latent)\n",
      "        print(\"Original shape:\", sample.shape)\n",
      "        print(\"Latent shape:\", latent.shape)\n",
      "        print(\"Reconstructed shape:\", recon.shape)\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    _example()\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(shared.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057e3ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brocode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
